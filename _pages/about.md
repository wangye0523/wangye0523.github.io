---
permalink: /
title: ""
excerpt: ""
author_profile: true
redirect_from: 
  - /about/
  - /about.html
---

{% if site.google_scholar_stats_use_cdn %}
{% assign gsDataBaseUrl = "https://cdn.jsdelivr.net/gh/" | append: site.repository | append: "@" %}
{% else %}
{% assign gsDataBaseUrl = "https://raw.githubusercontent.com/" | append: site.repository | append: "/" %}
{% endif %}
{% assign url = gsDataBaseUrl | append: "google-scholar-stats/gs_data_shieldsio.json" %}

<span class='anchor' id='about-me'></span>

Ye Wang, School of Artificial Intelligence, [Chongqing University of Posts and Telecommunications](https://english.cqupt.edu.cn/).

Dr. Wang received his Ph.D. in Computer Engineering from [Texas A&M University](https://engineering.tamu.edu/ce/index.html). His research focuses on natural language processing, particularly multimodal dialogue generation, intention reasoning, and affective computing. He has published widely in top-tier journals, including IEEE Transactions on Affective Computing (TAFFC), IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), IEEE Journal of Biomedical and Health Informatics (J-BHI), IEEE Transactions on Consumer Electronics (TCE), Information Fusion, and Information Processing & Management.

He has led research projects funded by the National Natural Science Foundation of China and provincial-level foundations. His work has been recognized with honors such as Best Paper Candidate at ISPCE-AS 2023 and Best Paper Award at the International Conference on Brain Informatics 2024. Before joining CQUPT, he worked as a research scientist at [Samsung Research America](https://sra.samsung.com/).

Dr. Wang is also dedicated to student mentorship. His students have received national innovation program awards, top prizes in competitions such as the Challenge Cup, RoboCom, and the MCM/ICM. Many of his graduates now work at leading tech companies including Tencent, ByteDance, and Xiaohongshu, or continue their studies at top universities such as the University of Michigan and Zhejiang University.

For detailed research papers, please refer to my [Google Scholar](https://scholar.google.com/citations?user=UNxKb0cAAAAJ&hl=zh-CN). 
For the Chinese version of my curriculum vitae, please refer to my [‰∏≠ÊñáÁâà‰∏™‰∫∫‰∏ªÈ°µ](https://faculty.cqupt.edu.cn/wangye/zh_CN/index.htm).

# üî•News 
- *2026.01*: One paper was accepted by the International Conference on Learning Representations (ICLR). LouisKV is proposed, which efficiently retrieves KV cache at semantic boundaries, boosting long-sequence reasoning performance by up to 4.7x: [[paper](https://openreview.net/forum?id=6RJ8fZwm4P&referrer=%5BAuthor%20Console%5D(%2Fgroup%3Fid%3DICLR.cc%2F2026%2FConference%2FAuthors%23your-submissions))]
- *2025.09*: One paper was accepted by IEEE Transactions on Circuits and Systems for Video Technology. A visual evidence-aware framework was presented that rectifies object hallucinations and restores missing content in LLM-based video captioning: [[paper](https://ieeexplore.ieee.org/document/11177574)][[code](https://github.com/no-zjc/VEaCap)]
- *2025.09*: One paper was accepted by Information Fusion. GCFA was proposed to tackle long-tailed medical text classification by fusing LLM-generated head/tail features and a medical agent attention, improving tail-class performance via semantic diversity and term emphasis: [[paper](https://www.sciencedirect.com/science/article/abs/pii/S1566253525007110)][[code](https://github.com/WQYwqy123456/GCFA-123#)]
- *2025.09*: One paper was accepted by IEEE Transactions on Consumer Electronics. We developed CRMED, a medical dialogue generation model that leverages LLMs with continuous entity reasoning to capture relationships between medical entities in multi-turn conversations, significantly improving response quality for consumer health technology applications: [[paper](https://ieeexplore.ieee.org/document/11123515)][[code](https://github.com/xinyang183/CRMED)]
- *2025.08*: One paper was accepted by IEEE Journal of Biomedical and Health Informatics (J-BHI). Chinese character structures and boundary features were leveraged to recognize unseen terms and confusing medical entities: [[paper](https://ieeexplore.ieee.org/document/11112630/authors)][[code](https://github.com/jl7650/CCS.git)]
- *2025.02*: One paper was accepted by Information Processing and Management. A hierarchical chat-based prompting strategy was proposed for MLLMs to improve spatio-temporal action detection in football by generating detailed, structured descriptions of fast-paced multi-player actions: [[paper](https://github.com/TristanAlkaid/HCBS)][[code](https://tristanalkaid.github.io/)]
- *2024.12*: The Best Conference Paper was awarded from the The 17th International Conference on Brain Informatics. To address catastrophic forgetting in class incremental learning, we introduced a multi-granularity balance strategy that combines batch-level weighted loss, task-level contrastive learning, and decision-level knowledge distillation: ([BI 2024](https://rdcu.be/edXQi))
- *2024.09*: One paper was accepted by IEEE Transactions on Affective Computing. DEDNet was proposed, which improves multimodal emotion recognition in conversations by disentangling inter-/intra-speaker emotional dependencies via relational subgraphs and incremental interaction: [[paper]](https://ieeexplore.ieee.org/abstract/document/10680310?casa_token=vcJgQz7-oOoAAAAA:aC1TU8fMzie06qcWov8N29Q5bDk7COkg8VwMmhZGSacbLCh0Rz0w8r8S9FUadoi8IMACLNxTbw)[[code](https://github.com/ZhangW1212)]



# üèÅ Research teams
- Mr. [Xuyang Zhou](https://tristanalkaid.github.io) (Ph.D. student)
- Mr. [Zixuan Wu](https://github.com/CQUPTWZX) (Ph.D. student)
- Mr. Pan Sun (MS student)
- Miss. Xiaolin Zhou (MS student)
- Mr. Maocai Dai (MS student)
- Miss. Hongbing Chen (MS student)
- Miss. Jie Yang (MS student)
- Mr. Haokun Ren (MS student)
- Mr. Yahui Lei (MS student)
- Mr. Siyi Liu (MS student)
- Mr. Gezhang Cao (MS student)
- Mr. Jingying Peng (MS student)
- Mr. Jun Hu (MS student)
- Mr. Hao You (MS student)
- Miss. Tingting Lei (MS student)
- Mr. Jie Tang (MS student)


# üéì Alumni
- Mr. [Yongliang Yang](https://asenniu.github.io/) (Tencent PCG)
- Mr. [Jiancheng Zhou](https://github.com/no-zjc/VEaCap) (Mashang Consumer Finance)
- Mr. [Wei Zhang](https://github.com/ZhangW1212) (Ph.D.@ South China University of Technology)
- Miss. [Qingyan Wang](https://github.com/WQYwqy123456/GCFA-123#) (Mobvista)
- Mr. [Xinyang Li](https://github.com/xinyang183/CRMED) (Chang'an)
- Mr. Zhuoyi Yu (MS@ University of Electronic Science and Technology of China)
- Mr. [Guanmeng Xian](https://gmxian.github.io/), Bachelor 2024 (MS@ Sichuan University)
- Miss. Daitianxia Li, Master 2024 (Chongqing City Management College)
- Mr. Zheng Wang, Master 2024 (Enmo tech)
- Mr. [Qi Wei](https://github.com/jl7650/CCS), Master 2024 (Guangdong Planning and Designing Institute of Telecommunications)
- Mr. Jingbo Liao, Master 2023 (Alibaba)
- Mr. Qianmengke Zhao, Master 2023 (Chongqing Rural Commercial Bank)
- Mr. Wenkang Lu, Master 2023 (Chang'an Tech)
- Mr. [Qi Cheng](https://www.linkedin.com/in/qi-cheng-4365a9249/), Bachelor 2023 (MS@ University of Michigan, Ann Arbor)
- Mr. Dongyu Xie, Bachelor 2023 (MS@ University of Electronic Science and Technology of China)
- Miss. Xinyi Gao, Bachelor 2023 (MS@ University of Rochester)

# üßëüèº‚Äçü§ù‚Äçüßëüèª Collaborators
- [Guoyin Wang](https://faculty.cqupt.edu.cn/wanggy/zh_CN/index.htm), Chongqing University of Posts and Telecommunications, China.
- [Hong Yu](https://faculty.cqupt.edu.cn/yuhong/zh_CN/index.htm), Chongqing University of Posts and Telecommunications, China.
- [Qun Liu](https://faculty.cqupt.edu.cn/liuqun/zh_CN/index.htm), Chongqing University of Posts and Telecommunications, China.
- [Li Liu](https://scholar.google.com/citations?user=uoNJ6goAAAAJ&hl=zh-CN), Chongqing University of Posts and Telecommunications, China.
- [Jiaxu Leng](https://scholar.google.com/citations?user=KpX-CCcAAAAJ&hl=zh-CN), Chongqing University of Posts and Telecommunications, China.
- [William K. Cheung](https://scholar.google.com/citations?user=e42JkYIAAAAJ&hl=zh-CN), Hong Kong Baptist University, Hong Kong SAR, China.
- [Lifeng Shen](https://www.lshenae.cn/), Hong Kong University of Science and Technology, Hong Kong SAR, China.
- [Mi Lu](https://scholar.google.com/citations?user=crjEvpQAAAAJ&hl=en), Texas A&M University, United States.
- [Yoonsuck Choe](https://scholar.google.com/citations?user=nFb_T4wAAAAJ&hl=en), Texas A&M University, United States.
- [Han Wang](https://scholar.google.com/citations?user=8MS58WkAAAAJ&hl=en), Samsung Research America, United States.
- [Fei Tao](https://scholar.google.com/citations?hl=zh-CN&user=KhWMky4AAAAJ), Amazon, United States.
- [Xinxiang Zhang](https://scholar.google.com/citations?user=OcCQAs4AAAAJ&hl=zh-CN), Southern Methodist University, United States.
- [Xiao Li](https://scholar.google.com/citations?user=y9iRoggAAAAJ&hl=en), Oxford University, United Kingdom.

# üè´ Educations
- Ph.D. Computer Engineering, Texas A&M University, Texas, United States. 2014.08 ~ 2019.12.
- M.Sc. Electrical Engineering, The University of Texas at Dallas, Texas, United States. 2012.08 ~ 2014.05.
- B.Eng. Microelectronics, Chongqing University of Posts and Telecommunications, Chongqing, China. 2007.09 ~ 2011.07.

# üìã Journal papers
- [9] Ye Wang, Jiancheng Zhou, Qun Liu*, Feng Hu, Guoyin Wang. Visual Evidence-aware for Object Hallucinations Rectification in LLM-based Video Captioning [J]. IEEE Transactions on Circuits and Systems for Video Technology (TCSVT), 2026. (SCI-1 Top, CCF-B)
- [8] Ye Wang, Qingyan Wang, Hong Yu, Jiang Xie, Feng Hu, Xiaoling Wang, Dajiang Lei*. GCFA: Generative class feature fusion with agent attention for medical text classification [J]. Information Fusion, V126, Part B, 103639, 2026. (SCI-1 Top)
- [7] Ye Wang, Xinyang Li, Hong Yu, Feng Hu, Guoyin Wang* and Dajiang Lei*. Continuous Entity Reasoning for Multi-Turn Medical Dialogue Generation [J]. IEEE Transactions on Consumer Electronics. V71, I4, pp. 10681-10694, 2025. (SCI 2)
- [6] Ye Wang, Qi Wei, Hong Yu, Guoyin Wang, Chunmeng Shi, Dajiang Lei*. Cross-Interaction of Chinese Characters Structures and Boundary Features for Improving Clinical Named Entity Recognition[J]. Journal of Biomedical and Health Informatics (JBHI). V29, I11, pp. 8508-8521, 2025. (SCI-1 Top)						
- [5] Xuyang Zhou, Ye Wang‚àó, Fei Tao, Hong Yu, Qun Liu. Hierarchical Chat-Based Strategies with MLLMs For Spatio-Temporal Action Detection [J].Information Processing and Management. V62, I4, 104094. 2025. (SCI-1 Top, CCF-B)		
- [4] Ye Wang, Wei Zhang, Ke Liu*, Wei Wu, Feng Hu, Hong Yu, Guoyin Wang. Dynamic Emotion-Dependent Network with Relational Subgraph Interaction for Multimodal Emotion Recognition [J]. IEEE Transactions on Affective Computing. V16, I2, pp. 712-712. 2025. (SCI-1 Top, CCF-B)						
- [3] Ye Wang, Zheng Wang, Hong Yu, Guoyin Wang* and Dajiang Lei*. The Interactive Fusion of Characters and Lexical Information for Chinese Named Entity Recognition [J]. Artificial Intelligence Review. V57, I258, pp. 1-21. 2024. (SCI-1 Top)
- [2] Ye Wang, Qianmengke Zhao, Qun Liu*, Guoyin Wang, Hong Yu, Li Liu, and Jiaxu Leng. KDDGAN: Knowledge-guided explicit feature disentanglement for Facial Attribute Editing [J]. IEEE Transactions on Consumer Electronics (TCE). V70, I1, pp. 2759-2772, Feb 2024. (SCI 2)						
- [1] Ye Wang, Xinxiang Zhang, Mi Lu, Han Wang, Yoonsuck Choe. Attention augmentation with multi-residual in bidirectional LSTM. Neurocomputing, V385, pp 340-347, 2020. (SCI-2 Top)						

# üìÉ Conference papers
- [4] Yan Xian, Hong Yu, Ye Wang, Guoyin Wang. A Novel Class Incremental Learning Method via Multi-granularity Balance Inspired by Human Granular Cognition Mechanism[C]. 2024 17th International Conference on Brain Informatics, pp 375‚Äì387, Bangkok, Thailand, 2024. (Best Conference Paper)
- [3] XinQiang Jiang, YingNan Geng, Yinzhou Xiong, Fei Tao, Ye Wang. A Privacy-aware Framework for Assessing and Recommending Short Video Advertisement[C]. 2023 IEEE International Symposium on Product Compliance Engineering - Asia (ISPCE-ASIA), pp 1-7, Shanghai, China, 2023. (Best Paper Candidate)
- [2] Jiaxu Leng, Ye Wang. RCNet: Recurrent Collaboration Network Guided by Facial Priors for Face Super-Resolution[C]. 2022 IEEE International Conference on Multimedia and Expo (ICME), pp 1-6, Taipei, Taiwan, 2022. (CCF-BÔºâ
- [1] Ye Wang, Han Wang, Xinxiang Zhang, Theodora Chaspari, Yoonsuck Choe, Mi Lu, An attention-aware bidirectional multi-residual recurrent neural network (abmrnn): A study about better short-term text classification[C]. 2019 IEEE International Conference on Acoustics, Speech and Signal Processing (ICASSP), pp 3582-3586, Brighton, UK, 2019. (CCF-B)						
						
# üåè Global attention
<div align=center> <a href='https://clustrmaps.com/site/1bxpb'  title='Visit tracker'><img src='//clustrmaps.com/map_v2.png?cl=292828&w=a&t=tt&d=ZfuNYkVmlF9O1cz_sbg-2nplj6eYBUDFG-G6L75zZxM&co=ffffff&ct=ffffff'/></a></div> 

# üì∞ Previous News
- *2024.08*: One paper was accepted by Artificial Intelligence Review. We proposed an interactive fusion approach that fully models the interaction between characters and lexical information through graph attention networks and secondary fusion, achieving more comprehensive feature representations and significantly improving performance in Chinese Named Entity Recognition:[[paper]](https://link.springer.com/article/10.1007/s10462-024-10891-3?utm_source=rct_congratemailt&utm_medium=email&utm_campaign=oa_20240816&utm_content=10.1007/s10462-024-10891-3)[[code](https://github.com/wangye0523/The-interactive-fusion-of-characters-and-lexical-information-for-Chinese-named-entity-recognition)]
- *2024.08*: One paper was accepted by Neural Computing and Applications. We proposed a self-supervised modal optimization transformer (SMOT) that reduces cross-modal distribution gaps by optimizing image features with paired captions and fusing them with complementary features, which enables more efficient learning, better generalization on small datasets, and improved performance in image captioning: [[paper]](https://link.springer.com/article/10.1007/s00521-024-10211-4)
- *2024.01*: One paper was accepted by IEEE Transactions on Consumer Electronics. We introduced a knowledge-guided explicit feature disentanglement network that transforms implicit feature representations into explicit semantics with prior knowledge, enabling independent manipulation of facial attributes in facial attribute editing: [[paper]](https://ieeexplore.ieee.org/document/10374272)
- *2023.11*: The Best Paper Candidate was awarded from the 2023 IEEE ISPCE-AS: ([ISPCE-AS2023](https://dl2link.com/ISPCE-AS2023/index.html))
- *2023.05*: Interviewed by People's Education(„Ää‰∫∫Ê∞ëÊïôËÇ≤„Äã): [[Link]](https://news.cqnews.net/1/detail/1109608325812756480/web/content_1109608325812756480.html) 
- *2023.03*: Interviewed by Chongqing Daily Newspaper(ÈáçÂ∫ÜÊó•Êä•Êñ∞Èóª‰ºöÂÆ¢ÂéÖ) about ChatGPT: [[Link]](https://v.douyin.com/i8Nre2Cx/) 
